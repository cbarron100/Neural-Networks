{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZvCueHfi2nz1mUpEvurag",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cbarron100/Neural-Networks/blob/main/CardiovacularClassificationTF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to create a classification model that will predict the survival of patients with heart failure from serum creatinine and ejection fraction, and other factors such as age, anemia, diabetes, and so on.\n",
        "\n",
        "Cardiovascular diseases (CVDs) are the number 1 cause of death globally, taking an estimated 17.9 million lives each year, which accounts for 31% of all deaths worldwide."
      ],
      "metadata": {
        "id": "fMg0Citj0_Fr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, InputLayer\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "cPWYp9UM0_La"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the data and let's take a look at the structure.\n",
        "\n",
        "After taking a look there seems to be some encoding needed to be done on several columns. They can be seen in the encode_col variable.\n",
        "\n",
        "We will also make our target and feature labels here."
      ],
      "metadata": {
        "id": "Ocz3afuG2Baa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/cardiovascular_data.csv')\n",
        "print(data.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GW3jht72SjH",
        "outputId": "f7991242-e5dd-4a07-f122-9bda48aaa82c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 299 entries, 0 to 298\n",
            "Data columns (total 14 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   age                       299 non-null    float64\n",
            " 1   anaemia                   299 non-null    object \n",
            " 2   creatinine_phosphokinase  299 non-null    int64  \n",
            " 3   diabetes                  299 non-null    object \n",
            " 4   ejection_fraction         299 non-null    int64  \n",
            " 5   high_blood_pressure       299 non-null    object \n",
            " 6   platelets                 299 non-null    float64\n",
            " 7   serum_creatinine          299 non-null    float64\n",
            " 8   serum_sodium              299 non-null    int64  \n",
            " 9   sex                       299 non-null    object \n",
            " 10  smoking                   299 non-null    object \n",
            " 11  time                      299 non-null    int64  \n",
            " 12  DEATH_EVENT               299 non-null    int64  \n",
            " 13  death_event               299 non-null    object \n",
            "dtypes: float64(3), int64(5), object(6)\n",
            "memory usage: 35.0+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(Counter(data['DEATH_EVENT']))\n",
        "\n",
        "\n",
        "X = data[['age',\n",
        "          'anaemia',\n",
        "          'creatinine_phosphokinase',\n",
        "          'diabetes',\n",
        "          'ejection_fraction',\n",
        "          'high_blood_pressure',\n",
        "          'platelets',\n",
        "          'serum_creatinine',\n",
        "          'serum_sodium',\n",
        "          'sex',\n",
        "          'smoking',\n",
        "          'time']]\n",
        "\n",
        "y = data['death_event']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDQY1LQ13W52",
        "outputId": "c3233b77-98d4-4586-e012-daf183b9659f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({0: 203, 1: 96})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have out feature and label columns. There are some columns that have strings so we will have to one-hot encode them."
      ],
      "metadata": {
        "id": "SYpelXuH4EdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "object_col = ['anaemia', 'diabetes', 'high_blood_pressure', 'sex', 'smoking']\n",
        "\n",
        "X = pd.get_dummies(X)\n"
      ],
      "metadata": {
        "id": "3wsTiMtB4P1U"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have numerical data in all of the columns, we can split the data. We are also going to change the scales of the data so that they all have an equal impact on the final prediction"
      ],
      "metadata": {
        "id": "Vmg39-VT5bq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
        "\n",
        "ct = ColumnTransformer([('numeric', StandardScaler(), ['age','creatinine_phosphokinase','ejection_fraction','platelets','serum_creatinine','serum_sodium','time'])])\n",
        "X_train = ct.fit_transform(X_train)\n",
        "X_test = ct.fit_transform(X_test)"
      ],
      "metadata": {
        "id": "lpE91V195gvf"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialising a LabelEncoder so that the label values are either a one or a 0 depending on if the person had cardiovascular disease or not"
      ],
      "metadata": {
        "id": "U_knL7fr6qjy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train.astype(str))\n",
        "y_test = le.fit_transform(y_test.astype(str))\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n"
      ],
      "metadata": {
        "id": "Jnvm7RUH6vST"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the data is prepared we can create a model. We will have an input layer with the corresponding number of features. Then the next layer will have 12 node with a ReLU activation and then finishing wiht 2 outputs with a softmax activation so that we get a percentage chance of which it could be.\n"
      ],
      "metadata": {
        "id": "thvI-wxh7vRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(InputLayer(X_train.shape[1], ))\n",
        "model.add(Dense(12, activation = 'relu'))\n",
        "model.add(Dense(y_train.shape[1], activation = 'softmax'))\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pNZdbIad70ac"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are going to train the model with out data. Then we are also going to present the metric of the model and see how well it could predict the CVD."
      ],
      "metadata": {
        "id": "QyXykyhY9iHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "batch = 16\n",
        "\n",
        "model.fit(X_train, y_train, epochs= num_epochs, batch_size = batch, verbose = 0)\n",
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "\n",
        "y_estimate = model.predict(X_test)\n",
        "y_estimate = np.argmax(y_estimate, axis = 1)\n",
        "y_true = np.argmax(y_test, axis = 1)\n",
        "\n",
        "print(f'Model loss: {loss}\\nModel accuracy: {acc}')\n",
        "print('Model F1 Score:', f1_score(y_true, y_estimate))\n",
        "print('Model Classification Report: \\n', classification_report(y_true, y_estimate))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skv4d1pF9nek",
        "outputId": "bcfc01c0-b0e0-466c-93c3-5d1c202357b0"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 275ms/step - loss: 0.7557 - accuracy: 0.6833\n",
            "2/2 [==============================] - 1s 718ms/step\n",
            "Model loss: 0.7557295560836792\n",
            "Model accuracy: 0.6833333373069763\n",
            "Model F1 Score: 0.5581395348837209\n",
            "Model Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.83      0.75        35\n",
            "           1       0.67      0.48      0.56        25\n",
            "\n",
            "    accuracy                           0.68        60\n",
            "   macro avg       0.68      0.65      0.66        60\n",
            "weighted avg       0.68      0.68      0.67        60\n",
            "\n"
          ]
        }
      ]
    }
  ]
}